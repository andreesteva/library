{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition a detection baseline for Yunzhu\n",
    " - edinburgh dataset + 'other' class\n",
    " - pigmented lesion malignant\n",
    " - pigmented lesion benign\n",
    " - epidermal lesion malignant\n",
    " - epidermal lesion benign\n",
    " - imagenet validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import lib\n",
    "from lib.taxonomy import loading \n",
    "from lib.taxonomy.utils import SynonymsList\n",
    "from lib.taxonomy import io\n",
    "\n",
    "imagenet_dir = '/media/esteva/ExtraDrive1/ILSVRC2014/val'\n",
    "train_dir = '/media/esteva/ExtraDrive1/ThrunResearch/data/skindata4/splits/detection/five-way/train'\n",
    "\n",
    "D = '/media/esteva/ExtraDrive1/ThrunResearch/data/skindata4'\n",
    "dataset_directory = os.path.join(D, 'images/')\n",
    "meta_file = os.path.join(D, 'meta.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta = json.load(open(meta_file))\n",
    "meta = [m for m in meta if loading.imageExists(m, dataset_directory)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Edinburgh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "1114\n"
     ]
    }
   ],
   "source": [
    "edinburgh = loading.getEntries(meta, 'database', 'edinburgh')\n",
    "print len(edinburgh)\n",
    "\n",
    "# Fix the naming convention issues of the top 9 categories (to dermal-tumor-benign, etc.)\n",
    "syns = SynonymsList()\n",
    "for m in edinburgh:\n",
    "    rootname = '-'.join(m['tax_path'][0])\n",
    "    rootrename = syns.synonymOf(rootname).split('-')\n",
    "    m['tax_path'][0] = rootrename\n",
    "    \n",
    "# Keep the 4 classes of interest\n",
    "edinburgh = [m for m in edinburgh if 'epidermal' in m['label'] or 'pigmented' in m['label']]\n",
    "print len(edinburgh)\n",
    "\n",
    "loading.setEntries(edinburgh, 'set_identifier', loading.TRAINING_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'epidermal-tumor-benign',\n",
       " 1: 'epidermal-tumor-malignant',\n",
       " 2: 'pigmented-lesion-benign',\n",
       " 3: 'pigmented-lesion-malignant'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in edinburgh:\n",
    "    if 'label' in m:\n",
    "        m['disease_name'] = m['label']\n",
    "        m['label'] = None\n",
    "\n",
    "# Assign nine-way rootnode classes.\n",
    "classes, labels = loading.rootNodeClasses(edinburgh)\n",
    "classnames = classes.values()\n",
    "loading.setEntries(edinburgh, 'label', labels)\n",
    "\n",
    "# Extract training paths and labels into a single list\n",
    "trainset = np.unique(loading.gatherPathsAndLabels(edinburgh, dataset_directory, loading.TRAINING_SET)).tolist()\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Imagenet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagenet = [os.path.join(imagenet_dir, im) for im in os.listdir(imagenet_dir)]\n",
    "imagenet = [im + ' 4' for im in imagenet]\n",
    "trainset.extend(imagenet)\n",
    "classnames = classes.values()\n",
    "classnames.extend(['imagenet'])\n",
    "\n",
    "classnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory structure with symlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "io.make_directory_structure(train_dir, classnames)\n",
    "syms_train = io.generate_symlinks(trainset, train_dir, classnames)\n",
    "\n",
    "for entry in syms_train:\n",
    "    src = entry.split()[0]\n",
    "    dst = entry.split()[1]\n",
    "    os.symlink(src, dst)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
