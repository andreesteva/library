{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connected Components Partition\n",
    " - Partitioning Strategy: Recursive Dividing N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import lib\n",
    "from lib.taxonomy.utils import SynonymsList\n",
    "from lib.notebooks.vis_utils import tic, toc\n",
    "from lib.taxonomy.loading import getEntryValues, gatherSynset, gatherPathsAndLabels, rootNode, rootNodeClasses, setEntries\n",
    "from lib.taxonomy.loading import imageExists\n",
    "from lib.taxonomy.loading import TRAINING_SET, TESTING_SET, NO_SET\n",
    "from lib.taxonomy.edge_extraction import *\n",
    "from lib.taxonomy.io import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_directory = '/ssd/esteva/skindata4/images/'\n",
    "meta_file = '/ssd/esteva/skindata4/meta.json'\n",
    "\n",
    "train_dir = '/ssd/esteva/skindata4/splits/recursive_dividing_N=1000/train'\n",
    "test_dir = '/ssd/esteva/skindata4/splits/recursive_dividing_N=1000/test'\n",
    "labels_file = '/ssd/esteva/skindata4/splits/recursive_dividing_N=1000/labels.txt'\n",
    "\n",
    "skin_prob = 0.4 \n",
    "tax_path_score = 0.8 \n",
    "N=1000\n",
    "\n",
    "curated_test_file = '/ssd/esteva/skindata4/test_sets/validation_set.txt'\n",
    "\n",
    "# Files with entries of the form [path/to/image] [label]\n",
    "# All basenames listed in excluded_datasets will be ommitted from train/val\n",
    "excluded_datasets = [ \n",
    "        '/ssd/esteva/skindata4/test_sets/dermoscopy_test.txt',\n",
    "        '/ssd/esteva/skindata4/test_sets/epidermal_test.txt',\n",
    "        '/ssd/esteva/skindata4/test_sets/melanocytic_test.txt'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FUNC: insert_datetime_field] Skipping 172 entries that could not load datetime\n"
     ]
    }
   ],
   "source": [
    "# We load in images that exist on our filesystem,\n",
    "meta = json.load(open(meta_file))\n",
    "meta = [m for m in meta if imageExists(m, dataset_directory)]\n",
    "\n",
    "# Connected components partition assigns one of TRAINING_SET or TESTING_SET to field 'set_identifier'\n",
    "partition_connected_components(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isic = getEntries(meta, 'database', 'isic')\n",
    "isic = [i for i in isic if 'label' in i and i['label'] in ['benign', 'malignant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep meta with desired skin probs and tax path scores\n",
    "meta = [m for m in meta if 'tax_path_score' in m and m['tax_path_score'] >= tax_path_score]\n",
    "meta = [m for m in meta if m['tax_path']]\n",
    "meta = [m for m in meta if 'skin_prob' in m and m['skin_prob'] >= skin_prob]\n",
    "meta.extend(isic)\n",
    "meta = [m for m in meta if m['set_identifier'] in [TRAINING_SET, TESTING_SET]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix the naming convention issues of the top 9 categories (to dermal-tumor-benign, etc.)\n",
    "syns = SynonymsList()\n",
    "for m in meta:\n",
    "    rootname = '-'.join(m['tax_path'][0])\n",
    "    rootrename = syns.synonymOf(rootname).split('-')\n",
    "    m['tax_path'][0] = rootrename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept Meta Entries: 146138\n",
      "0 cutaneous-lymphoma\n",
      "1 dermal-tumor-benign\n",
      "2 dermal-tumor-malignant\n",
      "3 epidermal-tumor-benign\n",
      "4 epidermal-tumor-malignant\n",
      "5 genodermatosis\n",
      "6 inflammatory\n",
      "7 pigmented-lesion-benign\n",
      "8 pigmented-lesion-malignant\n",
      "Size of meta_train 128038\n",
      "Size of meta_test 18100\n",
      "Keeping test set images that have been manually curated. Using curated test file: /ssd/esteva/skindata4/test_sets/validation_set.txt\n"
     ]
    }
   ],
   "source": [
    "# Rename 'label' field to 'disease_name'. 'label' will be used for integer labels.\n",
    "for m in meta:\n",
    "    if 'label' in m:\n",
    "        m['disease_name'] = m['label']\n",
    "        m['label'] = None\n",
    "\n",
    "print \"Kept Meta Entries: %d\" % len(meta)\n",
    "\n",
    "# Assign nine-way rootnode classes.\n",
    "classes, labels = rootNodeClasses(meta)\n",
    "setEntries(meta, 'label', labels)\n",
    "setEntries(meta, 'clinical_label', labels)\n",
    "\n",
    "meta_train = getEntries(meta, 'set_identifier', TRAINING_SET)\n",
    "meta_test = getEntries(meta, 'set_identifier', TESTING_SET)\n",
    "\n",
    "# Reassign to the training set new labels based on a recursive dividing treelearning partition.\n",
    "taxonomy = Taxonomy(meta_train)\n",
    "new_classes, new_names = recursive_division(taxonomy.top_node, N)\n",
    "sort_indices = np.argsort(new_names)\n",
    "new_classes = [new_classes[i] for i in sort_indices]\n",
    "new_names = [new_names[i] for i in sort_indices]\n",
    "for i, (new_class, new_name) in enumerate(zip(new_classes, new_names)):\n",
    "    new_name = new_name.strip('/').replace('/', '_')\n",
    "    for entry in new_class:\n",
    "        entry['label'] = i\n",
    "        entry['label_name'] = new_name\n",
    "print 'Applying TreeLearning: Recursive Dividing with N=%d' % N\n",
    "\n",
    "def collectSynset(meta_train):\n",
    "    \"\"\"Returns the synset and checks that it is sorted.\n",
    "\n",
    "    Args:\n",
    "      meta_train (list): list of dicts in skindata format. Must contain field 'label' and 'label_name'\n",
    "\n",
    "    Returns\n",
    "      Sorted list of class names in the format [label_name] [label].\n",
    "    \"\"\"\n",
    "    synset = []\n",
    "    for m in meta_train:\n",
    "        synset.append([m['label_name'], m['label']])\n",
    "    synset = {tuple(s) for s in synset}\n",
    "    synset = [list(s) for s in synset]\n",
    "    synset.sort(key=lambda x: x[0])\n",
    "    synset = [[str(ss) for ss in s] for s in synset]\n",
    "    synset = [\" \".join(s) for s in synset]\n",
    "\n",
    "    # run sort checks\n",
    "    ss = np.sort(synset)\n",
    "    for i,j in zip(ss, synset):\n",
    "        assert i == j\n",
    "\n",
    "    for i, j in zip([s.split()[1] for s in ss], [s.split()[1] for s in synset]):\n",
    "        assert i == j\n",
    "\n",
    "    return synset\n",
    "\n",
    "\n",
    "synset = collectSynset(meta_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14839\n",
      "Gathering paths and labels from the metadata\n",
      "Train and test share 0 images, according to filenames\n",
      "Train and val share 0 images, according to filenames\n",
      "Test and val share 0 images, according to filenames\n",
      "Dataset sizes (Based on Metadata):\n",
      "Train,\tVal,\tTest,\tTotal\n",
      "1036 \t0 \t118 \t1154\n",
      "7919 \t0 \t872 \t8791\n",
      "950 \t0 \t76 \t1026\n",
      "4567 \t0 \t641 \t5208\n",
      "8808 \t0 \t1461 \t10269\n",
      "5085 \t0 \t368 \t5453\n",
      "81907 \t0 \t10740 \t92647\n",
      "13088 \t0 \t380 \t13468\n",
      "4678 \t0 \t183 \t4861\n",
      "\n",
      "128038 0 14839\n",
      "\n",
      "Dataset sizes (Based on unique images):\n",
      "Train,\tVal,\tTest,\tTotal\n",
      "978 \t0 \t117 \t1095\n",
      "7618 \t0 \t858 \t8476\n",
      "925 \t0 \t76 \t1001\n",
      "4426 \t0 \t635 \t5061\n",
      "8443 \t0 \t1449 \t9892\n",
      "4959 \t0 \t366 \t5325\n",
      "77165 \t0 \t10666 \t87831\n",
      "13010 \t0 \t375 \t13385\n",
      "4595 \t0 \t170 \t4765\n",
      "# Unique Images in Training: 122119\n",
      "# Unique Images in Validation: 0\n",
      "# Unique Images in Testing: 14712\n",
      "\n",
      "Directory created: /ssd/esteva/skindata4/splits/nine-way/train\n",
      "Directory created: /ssd/esteva/skindata4/splits/nine-way/val\n",
      "Labels file created: /ssd/esteva/skindata4/splits/nine-way/labels.txt\n"
     ]
    }
   ],
   "source": [
    "# Exclude all specified datasets\n",
    "for exclusion_file in excluded_datasets:\n",
    "    filenames = [os.path.basename(line.strip().split()[0]) for line in open(exclusion_file).readlines()]\n",
    "\n",
    "    for fn in filenames:\n",
    "        ms = filename2meta(fn)\n",
    "        for m in ms:\n",
    "            m['set_identifier'] = NO_SET\n",
    "\n",
    "meta_test = getEntries(meta, 'set_identifier', TESTING_SET)\n",
    "print len(meta_test)\n",
    "\n",
    "print 'Gathering paths and labels from the metadata'\n",
    "trainset = np.unique(gatherPathsAndLabels(meta, dataset_directory, TRAINING_SET))\n",
    "testset = np.unique(gatherPathsAndLabels(meta, dataset_directory, TESTING_SET))\n",
    "no_set = np.unique(gatherPathsAndLabels(meta, dataset_directory, NO_SET))\n",
    "\n",
    "print_partition_statistics(meta, classes, dataset_directory)\n",
    "\n",
    "# Make training directory structure\n",
    "subclasses = [s.split()[1] for s in synset]\n",
    "make_directory_structure(train_dir, subclasses)\n",
    "make_directory_structure(test_dir, subclasses)\n",
    "\n",
    "syms_train = generate_symlinks(trainset, train_dir, subclasses)\n",
    "syms_test = generate_symlinks(testset, test_dir, subclasses)\n",
    "\n",
    "create_symlinks(syms_train)\n",
    "create_symlinks(syms_test)\n",
    "\n",
    "print 'Directory created: %s' % train_dir\n",
    "print 'Directory created: %s' % test_dir\n",
    "\n",
    "with open(labels_file, 'w') as f:\n",
    "    prefix = \"\"\n",
    "    for s in subclasses:\n",
    "        f.write(prefix)\n",
    "        f.write(s)\n",
    "        prefix = \"\\n\"\n",
    "print 'Labels file created: %s' % labels_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
