{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AAAI Submission 2017\n",
    "# Detection baseline\n",
    "# Make malignancy heatmap given an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from inception import inception_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 00884783-0-1.jpg\n",
      "Image 20447843-0-0.jpg\n",
      "Image 19193556-2-0.jpg\n",
      "Image 19193556-12-0.jpg\n",
      "Image 00884783-1-1.jpg\n",
      "Image 16449118-0-1.jpg\n",
      "Image 19193556-3-0.jpg\n",
      "Image 34141481-1-1.jpg\n",
      "Image 19193556-0-1.jpg\n",
      "Image 19193556-10-0.jpg\n",
      "Image 19193556-11-1.jpg\n",
      "Image 12870929-2-0.jpg\n",
      "Image 19193556-7-1.jpg\n",
      "Image 15245202-0-0.jpg\n",
      "Image 29449899-0-0.jpg\n",
      "Image 05644307-0-1.jpg\n",
      "Image 19193556-5-1.jpg\n",
      "Image 29847118-0-1.jpg\n",
      "Image 32357493-1-1.jpg\n",
      "Image 19193556-9-1.jpg\n",
      "Image 12870929-0-0.jpg\n",
      "Image 12870929-1-1.jpg\n",
      "Image 25727892-0-1.jpg\n",
      "Image 28552198-0-0.jpg\n",
      "Image 19193556-6-0.jpg\n",
      "Image 19193556-8-0.jpg\n",
      "Image 19193556-3-1.jpg\n",
      "Image 19193556-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-3-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 28552198-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-5-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00816546-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 07269046-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 14161046-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00884783-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00816546-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 25727892-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 23655319-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 12515284-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00816546-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 28602357-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 05518964-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 20447843-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 05518964-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 05518964-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 28552198-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 29847118-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 32357493-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 11150554-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 15245202-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 29449899-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 11150554-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 34141481-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00148049-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-4-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-4-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 16449118-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 07269046-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 05644307-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 18368837-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 12870929-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-3-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-2-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 16449118-1-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 23655319-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 32357493-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-8-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 28602357-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 07269046-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 16084634-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 11150554-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00148049-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 16449118-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 12870929-2-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-7-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-2-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-12-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 23655319-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 18368837-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-11-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00884783-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 28552198-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 32357493-2-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 34141481-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 32357493-2-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 05518964-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 16084634-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 32357493-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 34141481-2-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 11150554-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 12870929-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 23655319-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 12515284-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 00816546-1-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 34141481-2-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 10365468-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-10-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-2-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 07269046-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-6-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 14161046-0-1.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 19193556-9-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216 Image 34141481-0-0.jpg\n",
      "Succesfully loaded model from model.ckpt-4999 at step=4999.\n",
      "Processing 9184/9216\n"
     ]
    }
   ],
   "source": [
    "resize_factor = 1\n",
    "imagename= \"/media/esteva/ExtraDrive1/ThrunResearch/data/aaai2017/materials/\"\n",
    "# imagename = \"/media/esteva/ExtraDrive1/ThrunResearch/data/edinburgh/test_sets/pigmented/7/ML/B69b/B69b.png\"\n",
    "# imagename = \"/media/esteva/ExtraDrive1/ThrunResearch/data/edinburgh/test_sets/pigmented/8/MEL/B28/B28.png\"\n",
    "# imagename = \"/media/esteva/ExtraDrive1/ThrunResearch/data/edinburgh/test_sets/pigmented/8/MEL/D574c/D574c.png\"\n",
    "\n",
    "# Figure papers\n",
    "imagenames = \"\"\"\n",
    "/media/esteva/ExtraDrive1/ThrunResearch/data/aaai2017/figures/results_detection/00884783-1-1.jpg\n",
    "/media/esteva/ExtraDrive1/ThrunResearch/data/aaai2017/figures/results_detection/10365468-1-1.jpg\n",
    "/media/esteva/ExtraDrive1/ThrunResearch/data/aaai2017/figures/results_detection/16084634-0-0.jpg\n",
    "/media/esteva/ExtraDrive1/ThrunResearch/data/aaai2017/figures/results_detection/16449118-0-0.jpg\n",
    "\"\"\".strip().split()\n",
    "imagename = imagenames[0]\n",
    "\n",
    "# Detection test set\n",
    "detection_testset = \"/media/esteva/ExtraDrive1/ThrunResearch/data/aaai2017/images\"\n",
    "imagenames = os.listdir(detection_testset)\n",
    "imagenames = [i for i in imagenames if '.jpg' in i or '.png' in i]\n",
    "\n",
    "for imagename in imagenames:\n",
    "    print 'Image %s' % imagename\n",
    "    \n",
    "    # Output file name\n",
    "    file_name = '/tmp/aaai/' + os.path.basename(imagename) + '.mat'\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        continue\n",
    "    imagename = os.path.join(detection_testset, imagename)\n",
    "\n",
    "    image = scipy.misc.imread(imagename)\n",
    "    image = scipy.misc.imresize(image, (image.shape[0] / resize_factor, image.shape[1] / resize_factor, 3))\n",
    "    image = np.asarray(image, dtype=np.float32)\n",
    "    image /= np.max(image)\n",
    "\n",
    "    if image.shape[2] > 3:\n",
    "        image = image[:,:,:3]\n",
    "\n",
    "    assert image.shape[0] >= 299\n",
    "    assert image.shape[1] >= 299\n",
    "\n",
    "    # Pad image to raster scan across the whole thing\n",
    "    image = np.pad(image, pad_width=((149,149), (149,149), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    # image to patches\n",
    "    stride = 10\n",
    "\n",
    "    def im2patches(image, stride):\n",
    "        \"\"\"Tiles the image, striding, returning an N x 299 x 299 x 3 image array.\"\"\"    \n",
    "        stack = []\n",
    "        M = image.shape[0]\n",
    "        N = image.shape[1]\n",
    "        i_count = 0\n",
    "        for i in range(0, M-299, stride):\n",
    "            i_count += 1\n",
    "            j_count = 0        \n",
    "            for j in range(0, N-299, stride):\n",
    "                j_count += 1\n",
    "                patch = image[i:i+299, j:j+299, :]\n",
    "                patch = np.expand_dims(patch, 0)\n",
    "                stack.append(patch)\n",
    "        stack = np.vstack(stack)\n",
    "#         print i_count, j_count\n",
    "        return stack\n",
    "\n",
    "    stack = im2patches(image, stride)\n",
    "\n",
    "    # Build Tensorflow Graph. Create Session. Feed 299x299 image patches through network, collecting softmax.\n",
    "\n",
    "    batch_size = 32\n",
    "    checkpoint_dir = '/media/esteva/ExtraDrive1/ThrunResearch/tf_experiments/detection/five-way/train_fast/'\n",
    "    classes = open('/media/esteva/ExtraDrive1/ThrunResearch/data/skindata4/splits/detection/five-way/labels.txt').readlines()\n",
    "    num_classes = len(classes)\n",
    "#     for c in classes:\n",
    "#         print c\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "\n",
    "        input_op = tf.placeholder(tf.float32, shape=(batch_size, 299, 299, 3))\n",
    "        image_op = tf.sub(input_op, 0.5)\n",
    "        image_op = tf.mul(image_op, 2.0)\n",
    "\n",
    "        logits, _ = inception_model.inference(image_op, num_classes + 1)\n",
    "        softmax = tf.nn.softmax(logits)\n",
    "\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(\n",
    "            inception_model.MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            if os.path.isabs(ckpt.model_checkpoint_path):\n",
    "                # Restores from checkpoint with absolute path.\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                # Restores from checkpoint with relative path.\n",
    "                saver.restore(sess, os.path.join(checkpoint_dir,\n",
    "                                                 ckpt.model_checkpoint_path))\n",
    "\n",
    "            # Assuming model_checkpoint_path looks something like:\n",
    "            #   /my-favorite-path/imagenet_train/model.ckpt-0,\n",
    "            # extract global_step from it.\n",
    "            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "            print('Succesfully loaded model from %s at step=%s.' %\n",
    "                (ckpt.model_checkpoint_path, global_step))\n",
    "        else:\n",
    "            print('No checkpoint file found')\n",
    "\n",
    "        # Extract softmax over the stack\n",
    "        sm_stack = []\n",
    "        for i in range(0, len(stack), batch_size):\n",
    "            print '\\rProcessing %d/%d' % (i, len(stack)),\n",
    "            batch = stack[i:i+batch_size]\n",
    "            if len(batch) < batch_size: # We're at the end\n",
    "                n = len(batch)\n",
    "                batch = stack[-batch_size:]\n",
    "                sm = sess.run([softmax], feed_dict={input_op : batch})\n",
    "                sm = sm[0][-n:]\n",
    "            else:\n",
    "                sm = sess.run([softmax], feed_dict={input_op : batch})\n",
    "                sm = sm[0]\n",
    "            sm_stack.append(sm)\n",
    "\n",
    "    # Convert softmax stack back to heatmap\n",
    "\n",
    "    h = [s for ss in sm_stack for s in ss]\n",
    "    M = image.shape[0]\n",
    "    N = image.shape[1]\n",
    "\n",
    "    # Reshape into MM x NN array\n",
    "    MM = (M-299) // stride + 1 # Size of heatmap image\n",
    "    NN = (N-299) // stride + 1\n",
    "    h = [h[i:i+NN] for i in range(0, MM * NN, NN)]\n",
    "    h = np.array(h)\n",
    "\n",
    "    # Merge into background, benign, and malignant heatmap\n",
    "    h0 = h[:,:, 0] + h[:,:,3] # unused background & imagenet\n",
    "    hb = h[:, :, 1] + h[:, :, 4] # benign\n",
    "    hm = h[:,:, 2] + h[:,:,5] # malignant probs\n",
    "    h = np.stack((h0,hb,hm), axis=2)\n",
    "\n",
    "    # Malignant prediction map\n",
    "    l1 = np.argmax(h, axis=2)\n",
    "    l2 = np.max(h, axis=2)\n",
    "\n",
    "    def ready(h):\n",
    "        h = scipy.misc.imresize(h, (M-299, N-299), mode='F')\n",
    "    #     h = np.pad(h, pad_width=((149,149), (149,149)), mode='constant', constant_values=0)\n",
    "        return h\n",
    "\n",
    "    # Malignant probability map\n",
    "    m = ready(h[:,:,2])\n",
    "    b = ready(h[:,:,1])\n",
    "\n",
    "    # Expand probability map to original size & pad edges\n",
    "    # m = m[m < 0.5]\n",
    "    # b = b[b < 0.5]\n",
    "\n",
    "    imagename\n",
    "\n",
    "    # Pass heatmap to yunzhu in his required format\n",
    "    import scipy.io\n",
    "\n",
    "    def ready_yunzhu(ll):\n",
    "        tf_hw = 149\n",
    "        ll = scipy.misc.imresize(ll, (M-299, N-299), mode=\"F\")\n",
    "        ll = np.pad(ll, pad_width=((tf_hw,tf_hw), (tf_hw,tf_hw)), mode='constant', constant_values=0)\n",
    "        return ll\n",
    "\n",
    "    l1 = ready(l1)\n",
    "    l1 = np.round(l1)\n",
    "    l2 = ready(l2)\n",
    "    y = np.stack((l1,l2), axis=2)\n",
    "#     print y.shape\n",
    "\n",
    "    \n",
    "    mdict = {'heatmap' : y}\n",
    "\n",
    "    scipy.io.savemat(file_name, mdict, appendmat=True, format='5', \n",
    "                     long_field_names=False, do_compression=False, oned_as='row')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(m)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3289873e90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEECAYAAADUNKqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyAnCzIKcIMwsyAnCzIL+H3PabPTKXQwuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3288e17890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.zeros((h.shape))\n",
    "i = np.stack((z, h > 0.8, z), axis=2)\n",
    "plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 959, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
