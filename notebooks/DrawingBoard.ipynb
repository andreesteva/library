{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import lib\n",
    "from lib.taxonomy.utils import SynonymsList\n",
    "from lib.notebooks.vis_utils import tic, toc\n",
    "from lib.taxonomy.loading import getEntryValues, gatherSynset, gatherPathsAndLabels, rootNode, rootNodeClasses\n",
    "from lib.taxonomy.loading import setEntries\n",
    "from lib.taxonomy.loading import imageExists\n",
    "from lib.taxonomy.loading import TRAINING_SET, TESTING_SET, NO_SET, VALIDATION_SET\n",
    "from lib.taxonomy.graph_structure import Taxonomy, recursive_division\n",
    "from lib.taxonomy.edge_extraction import *\n",
    "from lib.taxonomy.io import generate_symlinks, make_directory_structure, create_symlinks\n",
    "from lib.taxonomy.io import print_partition_statistics\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "dataset_directory = '/archive/esteva/skindata4/images/'\n",
    "meta_file = '/archive/esteva/skindata4/meta.json'\n",
    "\n",
    "train_dir = '/archive/esteva/skindata4/splits/recursive_dividing_N=1000/train-tmp'\n",
    "test_dir = '/archive/esteva/skindata4/splits/recursive_dividing_N=1000/test-tmp'\n",
    "labels_file = '/archive/esteva/skindata4/splits/recursive_dividing_N=1000/labels-tmp.txt'\n",
    "\n",
    "skin_prob = 0.4\n",
    "tax_path_score = 0.8\n",
    "N=1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FUNC: insert_datetime_field] Skipping 172 entries that could not load datetime\n",
      "46288 Entries have the datetime metadata\n",
      "Calculating time-camera edge matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2652: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 / 43591 Elapsed Time: 6.21266889572 Time Remaining: 0.557573094064 Elapsed Time:  589.259970903\n",
      "Adding 43591 edges to the graph\n",
      "Adding 5183 turk edges to the graph\n",
      "Adding 2647 turk edges to the graph\n",
      "Adding 17204 dermquest edges to the graph\n",
      "Adding 21434 edges to the graph based on identical filenames\n",
      "We find 238254 connected components\n",
      "Proposing test set from /archive/esteva/skindata4/duplicate_urls_turk2.json\n",
      "Proposed Test Set has 20958 entries\n",
      "Partitioned Test Set has 19644 meta entries\n",
      "Kept Meta Entries: 135393\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    if os.path.exists(train_dir):\n",
    "        print 'Train dir %s exists, exiting' % train_dir\n",
    "        raise ValueError('gadfg')\n",
    "    if os.path.exists(test_dir):\n",
    "        print\n",
    "        'Test dir %s exists, exiting' % test_dir\n",
    "        raise ValueError('gadfg')\n",
    "\n",
    "    # We load in images that exist on our filesystem,\n",
    "    meta = json.load(open(meta_file))\n",
    "    meta = [m for m in meta if imageExists(m, dataset_directory)]\n",
    "\n",
    "    # Connected components partition assigns one of TRAINING_SET or TESTING_SET to field 'set_identifier'\n",
    "    partition_connected_components(meta)\n",
    "\n",
    "    # Keep meta with desired skin probs and tax path scores\n",
    "    meta = [m for m in meta if 'tax_path_score' in m and m['tax_path_score'] >= tax_path_score]\n",
    "    meta = [m for m in meta if m['tax_path']]\n",
    "    meta = [m for m in meta if 'skin_prob' in m and m['skin_prob'] >= skin_prob]\n",
    "    meta = [m for m in meta if m['set_identifier'] in [TRAINING_SET, TESTING_SET]]\n",
    "\n",
    "    # Fix the naming convention issues of the top 9 categories (to dermal-tumor-benign, etc.)\n",
    "    syns = SynonymsList()\n",
    "    for m in meta:\n",
    "        rootname = '-'.join(m['tax_path'][0])\n",
    "        rootrename = syns.synonymOf(rootname).split('-')\n",
    "        m['tax_path'][0] = rootrename\n",
    "\n",
    "    # Rename 'label' field to 'disease_name'. 'label' will be used for integer labels.\n",
    "    for m in meta:\n",
    "        if 'label' in m:\n",
    "            m['disease_name'] = m['label']\n",
    "            m['label'] = None\n",
    "\n",
    "    print \"Kept Meta Entries: %d\" % len(meta)\n",
    "\n",
    "    # Assign nine-way rootnode classes.\n",
    "    classes, labels = rootNodeClasses(meta)\n",
    "    setEntries(meta, 'label', labels)\n",
    "    setEntries(meta, 'clinical_label', labels)\n",
    "\n",
    "    meta_train = getEntries(meta, 'set_identifier', TRAINING_SET)\n",
    "    meta_test = getEntries(meta, 'set_identifier', TESTING_SET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Taxonomy\n",
      "Creating vertices...\n",
      "Distributing metadata entries...\n",
      "Initializing vertex variables...\n",
      "Identifying root nodes...\n",
      "Adding top node...\n",
      "Applying TreeLearning: Recursive Dividing with N=1000\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    taxonomy = Taxonomy(meta_train)\n",
    "    print 'Applying TreeLearning: Recursive Dividing with N=%d' % N\n",
    "    new_classes, new_names = recursive_division(taxonomy.top_node, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    sort_indices = np.argsort(new_names)\n",
    "    new_classes = [new_classes[i] for i in sort_indices]\n",
    "    new_names = [new_names[i] for i in sort_indices]\n",
    "    for i, (new_class, new_name) in enumerate(zip(new_classes, new_names)):\n",
    "        new_name = new_name.strip('/').replace('/', '_')\n",
    "        for entry in new_class:\n",
    "            entry['label'] = i\n",
    "            entry['label_name'] = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collectSynset(meta_train):\n",
    "    \"\"\"Returns the synset and checks that it is sorted.\n",
    "    \n",
    "    Args:\n",
    "        meta_train (list): list of dicts in skindata format. Must contain field 'label' and 'label_name'\n",
    "        \n",
    "    Returns\n",
    "        Sorted list of class names in the format [label_name] [label].\n",
    "    \"\"\"\n",
    "    synset = []\n",
    "    for m in meta_train:\n",
    "        synset.append([m['label_name'], m['label']])\n",
    "    synset = {tuple(s) for s in synset}\n",
    "    synset = [list(s) for s in synset]\n",
    "    synset.sort(key=lambda x: x[0])\n",
    "    synset = [[str(ss) for ss in s] for s in synset]\n",
    "    synset = [\" \".join(s) for s in synset]\n",
    "    \n",
    "    # run sort checks\n",
    "    ss = np.sort(synset)\n",
    "    for i,j in zip(ss, synset):\n",
    "        assert i == j\n",
    "        \n",
    "    for i, j in zip([s.split()[1] for s in ss], [s.split()[1] for s in synset]):\n",
    "        assert i == j\n",
    "        \n",
    "    return synset\n",
    "\n",
    "synset = collectSynset(meta_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping test set images that have been manually curated. Using curated test file: /archive/esteva/skindata4/splits/test_curated.txt\n",
      "14839\n",
      "Gathering paths and labels from the metadata\n",
      "Train and test share 0 images, according to filenames\n",
      "Train and val share 0 images, according to filenames\n",
      "Test and val share 0 images, according to filenames\n",
      "Dataset sizes (Based on Metadata):\n",
      "Train,\tVal,\tTest,\tTotal\n",
      "1036 \t0 \t118 \t1154\n",
      "7919 \t0 \t872 \t8791\n",
      "950 \t0 \t76 \t1026\n",
      "4567 \t0 \t641 \t5208\n",
      "8808 \t0 \t1461 \t10269\n",
      "5085 \t0 \t368 \t5453\n",
      "81907 \t0 \t10740 \t92647\n",
      "2777 \t0 \t380 \t3157\n",
      "4244 \t0 \t183 \t4427\n",
      "\n",
      "117293 0 14839\n",
      "\n",
      "Dataset sizes (Based on unique images):\n",
      "Train,\tVal,\tTest,\tTotal\n",
      "978 \t0 \t117 \t1095\n",
      "7618 \t0 \t858 \t8476\n",
      "925 \t0 \t76 \t1001\n",
      "4426 \t0 \t635 \t5061\n",
      "8443 \t0 \t1449 \t9892\n",
      "4959 \t0 \t366 \t5325\n",
      "77165 \t0 \t10666 \t87831\n",
      "2699 \t0 \t375 \t3074\n",
      "4161 \t0 \t170 \t4331\n",
      "# Unique Images in Training: 112417\n",
      "# Unique Images in Validation: 0\n",
      "# Unique Images in Testing: 14712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Keep only the test set entries that have passed manual curation\n",
    "    curated_test_file = '/archive/esteva/skindata4/splits/test_curated.txt'\n",
    "    print 'Keeping test set images that have been manually curated.',\n",
    "    print 'Using curated test file: %s' % curated_test_file\n",
    "    curated_test = [line.strip() for line in\n",
    "                    open(curated_test_file).readlines()]\n",
    "    curated_test = np.array([os.path.basename(t.split()[0]) for t in curated_test])\n",
    "\n",
    "    filename2meta = Field2meta(meta_test, field='filename')\n",
    "    for fn in curated_test:\n",
    "        ms = filename2meta(fn)\n",
    "        for m in ms:\n",
    "            m['cc_keep'] = True\n",
    "\n",
    "    for m in meta_test:\n",
    "        if 'cc_keep' not in m:\n",
    "            m['set_identifier'] = NO_SET\n",
    "\n",
    "    meta_test = getEntries(meta, 'set_identifier', TESTING_SET)\n",
    "    print len(meta_test)\n",
    "\n",
    "    print 'Gathering paths and labels from the metadata'\n",
    "    trainset = np.unique(gatherPathsAndLabels(meta, dataset_directory, TRAINING_SET))\n",
    "    valset = np.unique(gatherPathsAndLabels(meta, dataset_directory, VALIDATION_SET))\n",
    "    testset = np.unique(gatherPathsAndLabels(meta, dataset_directory, TESTING_SET))\n",
    "    no_set = np.unique(gatherPathsAndLabels(meta, dataset_directory, NO_SET))\n",
    "\n",
    "    print_partition_statistics(meta, classes, dataset_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Make testing directory structure\n",
    "    subclasses = np.unique([s.split()[0].split('_')[0] for s in synset])\n",
    "    make_directory_structure(test_dir, subclasses)\n",
    "    syms_test = generate_symlinks(testset, test_dir, subclasses)\n",
    "    create_symlinks(syms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cutaneous-lymphoma', 'dermal-tumor-benign',\n",
       "       'dermal-tumor-malignant 90', 'epidermal-tumor-benign',\n",
       "       'epidermal-tumor-malignant', 'genodermatosis', 'inflammatory',\n",
       "       'inflammatory 210', 'pigmented-lesion-benign',\n",
       "       'pigmented-lesion-benign 710', 'pigmented-lesion-malignant'], \n",
       "      dtype='|S27')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Make training directory structure\n",
    "    subclasses = np.unique([s.replace(' ', '_') for s in synset])\n",
    "    make_directory_structure(train_dir, subclasses)\n",
    "    syms_train = generate_symlinks(trainset, train_dir, subclasses)\n",
    "    create_symlinks(syms_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: /archive/esteva/skindata4/splits/recursive_dividing_N=1000/train-tmp\n",
      "Directory created: /archive/esteva/skindata4/splits/recursive_dividing_N=1000/test-tmp\n",
      "Labels file created: /archive/esteva/skindata4/splits/recursive_dividing_N=1000/labels-tmp.txt\n"
     ]
    }
   ],
   "source": [
    "    print 'Directory created: %s' % train_dir\n",
    "    print 'Directory created: %s' % test_dir\n",
    "\n",
    "    with open(labels_file, 'w') as f:\n",
    "        prefix = \"\"\n",
    "        for s in subclasses:\n",
    "            f.write(prefix)\n",
    "            f.write(s)\n",
    "            prefix = \"\\n\"\n",
    "    print 'Labels file created: %s' % labels_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1] == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2, 'd': 3}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = ['a','a','b','c','d']\n",
    "u = {v : i for i, v in enumerate(np.unique(v))}\n",
    "\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for uu in u:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "you jackass",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-232-474d04f0bdd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;34m'you jackass'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: you jackass"
     ]
    }
   ],
   "source": [
    "assert x == 0, \\\n",
    "    'you jackass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
